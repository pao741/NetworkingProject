{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import community as community_louvain\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subredditNames = [\"funny\",'AskReddit','gaming','aww','Music','pics','science','worldnews','videos','todayilearned',\n",
    "                 'movies','news','Showerthoughts','EarthPorn','gifs','IAmA','dankmemes','ComedyCemetery','Jokes',\n",
    "                  'LifeProTips','PrequelMemes','terriblefacebookmemes','books','mildlyinteresting','nottheonion','DIY',\n",
    "                 'sports','2meirl4meirl','space','gadgets','anime','memes','Unexpected','YouShouldKnow','programming',\n",
    "                 'bestof','MadeMeSmile','pettyrevenge','WTF','cringepics','wholesomegifs','cringe'\n",
    "                 , 'mildlyinfuriating','rage','leagueoflegends','pokemon','Minecraft','Games'\n",
    "                 ,'DotA2','starcraft','skyrim','mindcrack','arresteddevelopment','gameofthrones','doctorwho'\n",
    "                 ,'harrypotter','StarWars','DaftPunk','hiphopheads','geek','AdviceAnimals'\n",
    "                  ,'IdiotsInCars','circlejerk','facepalm'\n",
    "                  ,'TrollXChromosomes','AnimalsBeingJerks','youtubehaiku','woahdude','awwnime'\n",
    "                 ,'PerfectTiming','itookapicture','AbandonedPorn','techsupportgore','askscience'\n",
    "                 ,'explainlikeimfive','cats','corgi','food','teenagers','lifehacks','Frugal','Fitness','Art'\n",
    "                 ,'loseit','RedditLaqueristas','Random_Acts_Of_Amazon','politics','TrueReddit','atheism','lgbt'\n",
    "                 ,'TwoXChromosomes','MensRights','nba','soccer','hockey','nfl','Android'\n",
    "                 ,'technology','PewdiepieSubmissions','apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = 'scraped_data/submissions'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# print(onlyfiles)\n",
    "\n",
    "subreddits = [j + '.p' for j in subredditNames]\n",
    "\n",
    "inter = intersection(subreddits,onlyfiles)\n",
    "\n",
    "not_inter = [k for k in subreddits if k not in inter]\n",
    "print(not_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuthorList(df):\n",
    "    result_df = df.drop_duplicates(subset=['author'])\n",
    "    lst = result_df['author'].tolist()\n",
    "    if ('[deleted]' in lst):\n",
    "        lst.remove('[deleted]')    \n",
    "    return lst\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = set(lst1).intersection(lst2)\n",
    "    return lst3\n",
    "\n",
    "def union(lst1, lst2): \n",
    "    final_list = list(set(lst1) | set(lst2)) \n",
    "    return final_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuthorDict(subreddits):\n",
    "    authors_dict = {}\n",
    "    for subreddit in subreddits:\n",
    "        submission_file = open( \"scraped_data/submissions/\" + subreddit + \".p\", \"rb\" )\n",
    "        comment_file = open( \"scraped_data/comments/\" + subreddit + \".p\", \"rb\" )\n",
    "        load_submission = pickle.load(submission_file)\n",
    "        load_comment = pickle.load(comment_file)\n",
    "        submission_list = getAuthorList(load_submission)\n",
    "        comment_list = load_comment.tolist()\n",
    "        union_list = union(submission_list,comment_list)\n",
    "        authors_dict[subreddit] = union_list\n",
    "        submission_file.close()\n",
    "    return authors_dict\n",
    "\n",
    "authors_dict = getAuthorDict(subredditNames)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(number_of_nodes):\n",
    "    G = nx.Graph()\n",
    "    for i in range(number_of_nodes):\n",
    "        G.add_node(i)\n",
    "    return G\n",
    "\n",
    "def getFullyConnected(authors_dict, subreddits, G):\n",
    "    for i in range(len(subreddits)):\n",
    "        for j in range(i, len(subreddits)-1):\n",
    "            lst1 = authors_dict[subreddits[i]]\n",
    "            lst2 = authors_dict[subreddits[j+1]]\n",
    "            intersect_len = len(intersection(lst1, lst2))\n",
    "            if (intersect_len > 0):\n",
    "                G.add_edge(i,j+1,weight=intersect_len)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_graph = createGraph(len(subredditNames))\n",
    "getFullyConnected(authors_dict,subredditNames,fully_connected_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fully Connected Graph\n",
    "\n",
    "plt.figure(1,figsize=(8,8))\n",
    "nx.draw(fully_connected_graph, with_labels=True, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the highest weight edge per nodes\n",
    "\n",
    "graph_1 = createGraph(len(subredditNames))\n",
    "\n",
    "for node in range(len(subredditNames)-1):\n",
    "    node_edge_wight = [(node,i,fully_connected_graph.edges[i,node]['weight']) for i in list(fully_connected_graph.adj[node]) if i >= node]\n",
    "    u,v,w = max(node_edge_wight,key=itemgetter(2))\n",
    "    graph_1.add_edge(u,v,weight=w)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(12,12)) \n",
    "nx.draw_random(graph_1, with_labels=True)\n",
    "plt.show()b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subredditNames[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using louvain on highest weight per node\n",
    "\n",
    "partition = community_louvain.best_partition(graph_1,weight='weight')\n",
    "\n",
    "# draw the graph\n",
    "\n",
    "pos = nx.random_layout(graph_1)\n",
    "\n",
    "# color the nodes according to their partition\n",
    "\n",
    "cmap = cm.get_cmap('viridis', max(partition.values()) + 1)\n",
    "plt.figure(1,figsize=(12,12))\n",
    "nx.draw_networkx_nodes(graph_1, pos, partition.keys(), node_size=150, cmap=cmap, node_color=list(partition.values()))\n",
    "nx.draw_networkx_edges(graph_1, pos, alpha=0.5)\n",
    "nx.draw_networkx_labels(graph_1, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List community for graph_1 using louvain\n",
    "\n",
    "for i in list(set(partition.values())):\n",
    "    new_partition = dict(filter(lambda elem: elem[1] == i,partition.items()))\n",
    "    new_list = [subredditNames[key] for key in list(new_partition.keys())]\n",
    "    print('Community # ',i,\" list: \",new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Each node have at most 2 edges\n",
    "\n",
    "hist = []\n",
    "graph_2 = createGraph(len(subredditNames))\n",
    "\n",
    "for node in range(len(subredditNames)-1):\n",
    "    node_edge_wight = [(node,i,fully_connected_graph.edges[i,node]['weight']) for i in list(fully_connected_graph.adj[node]) if i >= node and i not in hist]\n",
    "    if (node_edge_wight):\n",
    "        u,v,w = max(node_edge_wight,key=itemgetter(2))\n",
    "        graph_2.add_edge(u,v,weight=w)\n",
    "    hist.append(v)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(12,12)) \n",
    "nx.draw_random(graph_2, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using louvain on a graph such that each node have at most 2 edges\n",
    "\n",
    "partition_2 = community_louvain.best_partition(graph_2,weight='weight')\n",
    "\n",
    "# draw the graph\n",
    "\n",
    "pos = nx.random_layout(graph_2)\n",
    "\n",
    "# color the nodes according to their partition\n",
    "\n",
    "cmap = cm.get_cmap('viridis', max(partition_2.values()) + 1)\n",
    "plt.figure(1,figsize=(12,12))\n",
    "nx.draw_networkx_nodes(graph_2, pos, partition_2.keys(), node_size=150, cmap=cmap, node_color=list(partition_2.values()))\n",
    "nx.draw_networkx_edges(graph_2, pos, alpha=0.5)\n",
    "nx.draw_networkx_labels(graph_2, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List community for graph_2 using louvain\n",
    "\n",
    "for i in list(set(partition_2.values())):\n",
    "    new_partition = dict(filter(lambda elem: elem[1] == i,partition_2.items()))\n",
    "    new_list = [subredditNames[key] for key in list(new_partition.keys())]\n",
    "    print('Community # ',i,\" list: \",new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select \n",
    "\n",
    "weight_list = []\n",
    "for (u, v, wt) in fully_connected_graph.edges.data('weight'):\n",
    "    weight_list.append((u,v,wt))\n",
    "    \n",
    "weight_list.sort(key=lambda tup:tup[2], reverse=True)\n",
    "\n",
    "graph_3 = createGraph(len(subredditNames))\n",
    "\n",
    "left_node = []\n",
    "right_node = []\n",
    "\n",
    "for i in range(100):\n",
    "    temp_list = [(u,v,w) for (u,v,w) in weight_list if u not in left_node and v not in right_node]\n",
    "    if (temp_list):\n",
    "        left,right,w = temp_list[0]\n",
    "        graph_3.add_edge(left,right,weight=w)\n",
    "        left_node.append(left)\n",
    "        right_node.append(right)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(12,12)) \n",
    "nx.draw_random(graph_3, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using louvain on a graph such that each node have at most 2 edges\n",
    "\n",
    "partition_3 = community_louvain.best_partition(graph_3,weight='weight')\n",
    "\n",
    "# draw the graph\n",
    "\n",
    "pos = nx.random_layout(graph_3)\n",
    "\n",
    "# color the nodes according to their partition\n",
    "\n",
    "cmap = cm.get_cmap('viridis', max(partition_3.values()) + 1)\n",
    "plt.figure(1,figsize=(12,12))\n",
    "nx.draw_networkx_nodes(graph_3, pos, partition_3.keys(), node_size=150, cmap=cmap, node_color=list(partition_3.values()))\n",
    "nx.draw_networkx_edges(graph_3, pos, alpha=0.5)\n",
    "nx.draw_networkx_labels(graph_3, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List community for graph_3 using louvain\n",
    "\n",
    "for i in list(set(partition_3.values())):\n",
    "    new_partition = dict(filter(lambda elem: elem[1] == i,partition_3.items()))\n",
    "    new_list = [subredditNames[key] for key in list(new_partition.keys())]\n",
    "    print('Community # ',i,\" list: \",new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import kernighan_lin_bisection\n",
    "\n",
    "c = list(kernighan_lin_bisection(G, partition=None, max_iter=37, weight='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "import itertools\n",
    "from networkx import edge_betweenness_centrality as betweenness\n",
    "\n",
    "def heaviest(G):\n",
    "    u, v, w = max(G.edges(data='weight'), key=itemgetter(2))\n",
    "    return (u, v)\n",
    "\n",
    "def most_central_edge(G):\n",
    "    centrality = betweenness(G, weight=\"weight\")\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "k = \n",
    "comp = girvan_newman(G, most_valuable_edge=most_central_edge)\n",
    "limited = itertools.takewhile(lambda c: len(c) <= k, comp)\n",
    "for communities in limited:\n",
    "    print(tuple(sorted(c) for c in communities))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girvan_community = [0, 1, 2, 5, 6, 7, 9, 10, 12, 14, 19, 23, 24, 86], [3, 4, 8, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99], [11, 51], [36], [38], [61, 63, 68, 84, 85, 97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in girvan_community:\n",
    "    new_list = [subredditNames[key] for key in i]\n",
    "    print(\"list: \",new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest(G):\n",
    "    u, v, w = min(G.edges(data='weight'), key=itemgetter(2))\n",
    "    return (u, v, w)\n",
    "\n",
    "u,v,w = lowest(G)\n",
    "while (w < 100):\n",
    "    G.remove_edge(u,v)\n",
    "    u ,v,w = lowest(G)\n",
    "    print(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
